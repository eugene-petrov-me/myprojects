{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9adac2ab",
   "metadata": {},
   "source": [
    "# Data Ingestion Pipeline - Codecademy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe773ddb",
   "metadata": {},
   "source": [
    "For this project, you’ll build a data engineering pipeline to regularly transform a messy database into a clean source of truth for an analytics team.\n",
    "\n",
    "### Scenario\n",
    "You’ll be working with a mock database of long-term cancelled subscribers for a fictional subscription company. This database is regularly updated from multiple sources, and needs to be routinely cleaned and transformed into usable shape with as little human intervention as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8022b23",
   "metadata": {},
   "source": [
    "### Project Objectives\n",
    "* Complete a project to add to your portfolio\n",
    "* Use Jupyter notebooks to explore and clean a dataset\n",
    "* Use Python to automate data cleaning and transformation using unit tests and error logging\n",
    "* Use Bash scripts to automate file management and run scripts\n",
    "\n",
    "### Prerequisites\n",
    "* Intermediate and Advanced Python 3\n",
    "* Pandas\n",
    "* Bash Scripting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b96bb",
   "metadata": {},
   "source": [
    "## Inspect and Clean the data\n",
    "Import the tables in cademycode.db as dataframes. Inspect the tables for missing or invalid data and perform any data cleaning operations you think are necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e20821",
   "metadata": {},
   "source": [
    "Start by importing libraries and creating a connection to the database and a cursor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99542bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564e688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"cademycode.db\")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e2da47",
   "metadata": {},
   "source": [
    "Explore what tables there are in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a41730f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cademycode_students',\n",
       "  'CREATE TABLE cademycode_students (\\n\\tuuid INTEGER, \\n\\tname VARCHAR, \\n\\tdob VARCHAR, \\n\\tsex TEXT, \\n\\tcontact_info JSON, \\n\\tjob_id VARCHAR, \\n\\tnum_course_taken VARCHAR, \\n\\tcurrent_career_path_id VARCHAR, \\n\\ttime_spent_hrs VARCHAR\\n)'),\n",
       " ('cademycode_courses',\n",
       "  'CREATE TABLE cademycode_courses (\\n\\tcareer_path_id BIGINT, \\n\\tcareer_path_name TEXT, \\n\\thours_to_complete BIGINT\\n)'),\n",
       " ('cademycode_student_jobs',\n",
       "  'CREATE TABLE cademycode_student_jobs (\\n\\tjob_id BIGINT, \\n\\tjob_category TEXT, \\n\\tavg_salary BIGINT\\n)'),\n",
       " ('students_data',\n",
       "  'CREATE TABLE \"students_data\" (\\n\"index\" INTEGER,\\n  \"uuid\" INTEGER,\\n  \"name\" TEXT,\\n  \"dob\" TEXT,\\n  \"sex\" TEXT,\\n  \"mailing_address\" TEXT,\\n  \"email\" TEXT,\\n  \"job_id\" INTEGER,\\n  \"num_course_taken\" INTEGER,\\n  \"current_career_path_id\" INTEGER,\\n  \"time_spent_hrs\" REAL,\\n  \"career_path_name\" TEXT,\\n  \"hours_to_complete\" REAL,\\n  \"job_category\" TEXT,\\n  \"avg_salary\" INTEGER,\\n  \"_completed_path\" INTEGER\\n)'),\n",
       " ('ix_students_data_index',\n",
       "  'CREATE INDEX \"ix_students_data_index\"ON \"students_data\" (\"index\")')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_query = cur.execute(\"\"\"SELECT name, sql FROM sqlite_master\"\"\")\n",
    "schema_query.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baebbbe3",
   "metadata": {},
   "source": [
    "###  Import and explore 'cademycode_students' table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2c540d",
   "metadata": {},
   "source": [
    "Create a query and read it into a dataframe.\n",
    "Then we analyze the dataframe to see what data there is and if need to clean it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b3bc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_query = \"\"\"SELECT * FROM cademycode_students\"\"\"\n",
    "df_students = pd.read_sql_query(students_query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50571b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students DF info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   uuid                    5000 non-null   int64 \n",
      " 1   name                    5000 non-null   object\n",
      " 2   dob                     5000 non-null   object\n",
      " 3   sex                     5000 non-null   object\n",
      " 4   contact_info            5000 non-null   object\n",
      " 5   job_id                  4995 non-null   object\n",
      " 6   num_course_taken        4749 non-null   object\n",
      " 7   current_career_path_id  4529 non-null   object\n",
      " 8   time_spent_hrs          4529 non-null   object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 351.7+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"Students DF info\")\n",
    "df_students.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "988b84c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Students DF first 10 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>sex</th>\n",
       "      <th>contact_info</th>\n",
       "      <th>job_id</th>\n",
       "      <th>num_course_taken</th>\n",
       "      <th>current_career_path_id</th>\n",
       "      <th>time_spent_hrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Annabelle Avery</td>\n",
       "      <td>1943-07-03</td>\n",
       "      <td>F</td>\n",
       "      <td>{\"mailing_address\": \"303 N Timber Key, Irondal...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Micah Rubio</td>\n",
       "      <td>1991-02-07</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"767 Crescent Fair, Shoals...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hosea Dale</td>\n",
       "      <td>1989-12-07</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"P.O. Box 41269, St. Bonav...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mariann Kirk</td>\n",
       "      <td>1988-07-31</td>\n",
       "      <td>F</td>\n",
       "      <td>{\"mailing_address\": \"517 SE Wintergreen Isle, ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Lucio Alexander</td>\n",
       "      <td>1963-08-31</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"18 Cinder Cliff, Doyles b...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Shavonda Mcmahon</td>\n",
       "      <td>1989-10-15</td>\n",
       "      <td>F</td>\n",
       "      <td>{\"mailing_address\": \"P.O. Box 81591, Tarpon Sp...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Terrell Bleijenberg</td>\n",
       "      <td>1959-05-05</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"P.O. Box 53471, Oskaloosa...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Stanford Allan</td>\n",
       "      <td>1997-11-22</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"255 Spring Avenue, Point ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Tricia Delacruz</td>\n",
       "      <td>1961-10-20</td>\n",
       "      <td>F</td>\n",
       "      <td>{\"mailing_address\": \"997 Dewy Apple, Lake Lind...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Regenia van der Helm</td>\n",
       "      <td>1999-02-23</td>\n",
       "      <td>N</td>\n",
       "      <td>{\"mailing_address\": \"220 Middle Ridge, Falcon ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uuid                  name         dob sex  \\\n",
       "0     1       Annabelle Avery  1943-07-03   F   \n",
       "1     2           Micah Rubio  1991-02-07   M   \n",
       "2     3            Hosea Dale  1989-12-07   M   \n",
       "3     4          Mariann Kirk  1988-07-31   F   \n",
       "4     5       Lucio Alexander  1963-08-31   M   \n",
       "5     6      Shavonda Mcmahon  1989-10-15   F   \n",
       "6     7   Terrell Bleijenberg  1959-05-05   M   \n",
       "7     8        Stanford Allan  1997-11-22   M   \n",
       "8     9       Tricia Delacruz  1961-10-20   F   \n",
       "9    10  Regenia van der Helm  1999-02-23   N   \n",
       "\n",
       "                                        contact_info job_id num_course_taken  \\\n",
       "0  {\"mailing_address\": \"303 N Timber Key, Irondal...    7.0              6.0   \n",
       "1  {\"mailing_address\": \"767 Crescent Fair, Shoals...    7.0              5.0   \n",
       "2  {\"mailing_address\": \"P.O. Box 41269, St. Bonav...    7.0              8.0   \n",
       "3  {\"mailing_address\": \"517 SE Wintergreen Isle, ...    6.0              7.0   \n",
       "4  {\"mailing_address\": \"18 Cinder Cliff, Doyles b...    7.0             14.0   \n",
       "5  {\"mailing_address\": \"P.O. Box 81591, Tarpon Sp...    6.0             10.0   \n",
       "6  {\"mailing_address\": \"P.O. Box 53471, Oskaloosa...    2.0              9.0   \n",
       "7  {\"mailing_address\": \"255 Spring Avenue, Point ...    3.0              3.0   \n",
       "8  {\"mailing_address\": \"997 Dewy Apple, Lake Lind...    1.0              6.0   \n",
       "9  {\"mailing_address\": \"220 Middle Ridge, Falcon ...    5.0              7.0   \n",
       "\n",
       "  current_career_path_id time_spent_hrs  \n",
       "0                    1.0           4.99  \n",
       "1                    8.0            4.4  \n",
       "2                    8.0           6.74  \n",
       "3                    9.0          12.31  \n",
       "4                    3.0           5.64  \n",
       "5                    3.0          10.12  \n",
       "6                    8.0          24.17  \n",
       "7                    1.0          19.54  \n",
       "8                    9.0           1.75  \n",
       "9                    6.0          13.55  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nStudents DF first 10 rows\")\n",
    "df_students.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7f317b",
   "metadata": {},
   "source": [
    "From the dataframe info we know there are missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1859c5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uuid                      0.00\n",
       "name                      0.00\n",
       "dob                       0.00\n",
       "sex                       0.00\n",
       "contact_info              0.00\n",
       "job_id                    0.10\n",
       "num_course_taken          5.02\n",
       "current_career_path_id    9.42\n",
       "time_spent_hrs            9.42\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students.isna().sum() / df_students.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ce9e9",
   "metadata": {},
   "source": [
    "Inspect examples of missing values for each of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "142b242f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_id values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>sex</th>\n",
       "      <th>contact_info</th>\n",
       "      <th>job_id</th>\n",
       "      <th>num_course_taken</th>\n",
       "      <th>current_career_path_id</th>\n",
       "      <th>time_spent_hrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>163</td>\n",
       "      <td>Glen Riley</td>\n",
       "      <td>2002-08-22</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"P.O. Box 37267, Cornlea v...</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>758</td>\n",
       "      <td>Mercedez Vorberg</td>\n",
       "      <td>2002-03-25</td>\n",
       "      <td>F</td>\n",
       "      <td>{\"mailing_address\": \"284 Cedar Seventh, Virden...</td>\n",
       "      <td>None</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>855</td>\n",
       "      <td>Kurt Ho</td>\n",
       "      <td>2002-05-29</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"P.O. Box 27254, Olin, New...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>1030</td>\n",
       "      <td>Penny Gaines</td>\n",
       "      <td>2002-03-01</td>\n",
       "      <td>N</td>\n",
       "      <td>{\"mailing_address\": \"138 Misty Vale, Stockton ...</td>\n",
       "      <td>None</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>1543</td>\n",
       "      <td>Frederick Reilly</td>\n",
       "      <td>2002-11-13</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"P.O. Box 40769, Quakervil...</td>\n",
       "      <td>None</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uuid              name         dob sex  \\\n",
       "162    163        Glen Riley  2002-08-22   M   \n",
       "757    758  Mercedez Vorberg  2002-03-25   F   \n",
       "854    855           Kurt Ho  2002-05-29   M   \n",
       "1029  1030      Penny Gaines  2002-03-01   N   \n",
       "1542  1543  Frederick Reilly  2002-11-13   M   \n",
       "\n",
       "                                           contact_info job_id  \\\n",
       "162   {\"mailing_address\": \"P.O. Box 37267, Cornlea v...   None   \n",
       "757   {\"mailing_address\": \"284 Cedar Seventh, Virden...   None   \n",
       "854   {\"mailing_address\": \"P.O. Box 27254, Olin, New...   None   \n",
       "1029  {\"mailing_address\": \"138 Misty Vale, Stockton ...   None   \n",
       "1542  {\"mailing_address\": \"P.O. Box 40769, Quakervil...   None   \n",
       "\n",
       "     num_course_taken current_career_path_id time_spent_hrs  \n",
       "162               8.0                    3.0            5.7  \n",
       "757              15.0                    4.0           4.14  \n",
       "854               0.0                    8.0          23.72  \n",
       "1029             15.0                    4.0          16.25  \n",
       "1542              7.0                    9.0          21.32  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"job_id values\")\n",
    "df_students[df_students['job_id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbd9640a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_course_taken values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>sex</th>\n",
       "      <th>contact_info</th>\n",
       "      <th>job_id</th>\n",
       "      <th>num_course_taken</th>\n",
       "      <th>current_career_path_id</th>\n",
       "      <th>time_spent_hrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Doug Browning</td>\n",
       "      <td>1970-06-08</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"P.O. Box 15845, Devine, F...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Damon Schrauwen</td>\n",
       "      <td>1953-10-31</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"P.O. Box 84659, Maben, Ge...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>Alisa Neil</td>\n",
       "      <td>1977-05-28</td>\n",
       "      <td>F</td>\n",
       "      <td>{\"mailing_address\": \"16 View Annex, Mosses, No...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>Chauncey Hooper</td>\n",
       "      <td>1962-04-07</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"955 Dewy Flat, Slaughterv...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81</td>\n",
       "      <td>Ellyn van Heest</td>\n",
       "      <td>1984-06-28</td>\n",
       "      <td>F</td>\n",
       "      <td>{\"mailing_address\": \"872 Cider Glade, Chicken,...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>4890</td>\n",
       "      <td>Tegan Cochran</td>\n",
       "      <td>1970-11-08</td>\n",
       "      <td>F</td>\n",
       "      <td>{\"mailing_address\": \"106 Sunny Nook, Vernal, G...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>4899</td>\n",
       "      <td>Ruthann Oliver</td>\n",
       "      <td>1998-05-22</td>\n",
       "      <td>F</td>\n",
       "      <td>{\"mailing_address\": \"644 Merry Island, Green V...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914</th>\n",
       "      <td>4915</td>\n",
       "      <td>Ernest Holmes</td>\n",
       "      <td>1995-03-11</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"872 Wintergreen Harbor, G...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>4981</td>\n",
       "      <td>Brice Franklin</td>\n",
       "      <td>1946-12-01</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"947 Panda Way, New Bedfor...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>4986</td>\n",
       "      <td>Russel Vonck</td>\n",
       "      <td>1994-09-07</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"815 Middle Timber Corner,...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uuid             name         dob sex  \\\n",
       "25      26    Doug Browning  1970-06-08   M   \n",
       "26      27  Damon Schrauwen  1953-10-31   M   \n",
       "51      52       Alisa Neil  1977-05-28   F   \n",
       "70      71  Chauncey Hooper  1962-04-07   M   \n",
       "80      81  Ellyn van Heest  1984-06-28   F   \n",
       "...    ...              ...         ...  ..   \n",
       "4889  4890    Tegan Cochran  1970-11-08   F   \n",
       "4898  4899   Ruthann Oliver  1998-05-22   F   \n",
       "4914  4915    Ernest Holmes  1995-03-11   M   \n",
       "4980  4981   Brice Franklin  1946-12-01   M   \n",
       "4985  4986     Russel Vonck  1994-09-07   M   \n",
       "\n",
       "                                           contact_info job_id  \\\n",
       "25    {\"mailing_address\": \"P.O. Box 15845, Devine, F...    7.0   \n",
       "26    {\"mailing_address\": \"P.O. Box 84659, Maben, Ge...    4.0   \n",
       "51    {\"mailing_address\": \"16 View Annex, Mosses, No...    5.0   \n",
       "70    {\"mailing_address\": \"955 Dewy Flat, Slaughterv...    3.0   \n",
       "80    {\"mailing_address\": \"872 Cider Glade, Chicken,...    3.0   \n",
       "...                                                 ...    ...   \n",
       "4889  {\"mailing_address\": \"106 Sunny Nook, Vernal, G...    5.0   \n",
       "4898  {\"mailing_address\": \"644 Merry Island, Green V...    3.0   \n",
       "4914  {\"mailing_address\": \"872 Wintergreen Harbor, G...    7.0   \n",
       "4980  {\"mailing_address\": \"947 Panda Way, New Bedfor...    4.0   \n",
       "4985  {\"mailing_address\": \"815 Middle Timber Corner,...    5.0   \n",
       "\n",
       "     num_course_taken current_career_path_id time_spent_hrs  \n",
       "25               None                    5.0           1.92  \n",
       "26               None                   10.0           3.73  \n",
       "51               None                    8.0          22.86  \n",
       "70               None                    3.0           3.97  \n",
       "80               None                   10.0          12.39  \n",
       "...               ...                    ...            ...  \n",
       "4889             None                    8.0          22.75  \n",
       "4898             None                    7.0          21.27  \n",
       "4914             None                    9.0           26.5  \n",
       "4980             None                    5.0           8.66  \n",
       "4985             None                    5.0          16.44  \n",
       "\n",
       "[251 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"num_course_taken values\")\n",
    "df_students[df_students['num_course_taken'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05e240a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_career_path_id values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>sex</th>\n",
       "      <th>contact_info</th>\n",
       "      <th>job_id</th>\n",
       "      <th>num_course_taken</th>\n",
       "      <th>current_career_path_id</th>\n",
       "      <th>time_spent_hrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Norene Dalton</td>\n",
       "      <td>1976-04-30</td>\n",
       "      <td>F</td>\n",
       "      <td>{\"mailing_address\": \"130 Wishing Essex, Branch...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Sofia van Steenbergen</td>\n",
       "      <td>1990-02-21</td>\n",
       "      <td>N</td>\n",
       "      <td>{\"mailing_address\": \"634 Clear Barn Dell, Beam...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Christoper Warner</td>\n",
       "      <td>1989-12-28</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"556 Stony Highlands, Drai...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>Antony Horne</td>\n",
       "      <td>1996-05-29</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"P.O. Box 78685, Lenox, Te...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>Omar Bunk</td>\n",
       "      <td>1955-11-08</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"445 Dale Hollow, Vermont ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4904</th>\n",
       "      <td>4905</td>\n",
       "      <td>Eduardo Daniel</td>\n",
       "      <td>2004-06-18</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"598 Deer Trace, Forest Gr...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>4923</td>\n",
       "      <td>Francisco van Ede</td>\n",
       "      <td>1961-04-26</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"282 Fourth Trace, Carter ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>4949</td>\n",
       "      <td>Dewitt van Malsem</td>\n",
       "      <td>1949-03-08</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"423 Course Trail, Wilmot,...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>4957</td>\n",
       "      <td>Todd Stamhuis</td>\n",
       "      <td>1961-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"251 Grand Rose Underpass,...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>4975</td>\n",
       "      <td>Jorge Creelman</td>\n",
       "      <td>1944-11-24</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"919 Well Overpass, Linden...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>471 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uuid                   name         dob sex  \\\n",
       "15      16          Norene Dalton  1976-04-30   F   \n",
       "19      20  Sofia van Steenbergen  1990-02-21   N   \n",
       "30      31      Christoper Warner  1989-12-28   M   \n",
       "49      50           Antony Horne  1996-05-29   M   \n",
       "54      55              Omar Bunk  1955-11-08   M   \n",
       "...    ...                    ...         ...  ..   \n",
       "4904  4905         Eduardo Daniel  2004-06-18   M   \n",
       "4922  4923      Francisco van Ede  1961-04-26   M   \n",
       "4948  4949      Dewitt van Malsem  1949-03-08   M   \n",
       "4956  4957          Todd Stamhuis  1961-06-15   M   \n",
       "4974  4975         Jorge Creelman  1944-11-24   M   \n",
       "\n",
       "                                           contact_info job_id  \\\n",
       "15    {\"mailing_address\": \"130 Wishing Essex, Branch...    6.0   \n",
       "19    {\"mailing_address\": \"634 Clear Barn Dell, Beam...    7.0   \n",
       "30    {\"mailing_address\": \"556 Stony Highlands, Drai...    2.0   \n",
       "49    {\"mailing_address\": \"P.O. Box 78685, Lenox, Te...    3.0   \n",
       "54    {\"mailing_address\": \"445 Dale Hollow, Vermont ...    3.0   \n",
       "...                                                 ...    ...   \n",
       "4904  {\"mailing_address\": \"598 Deer Trace, Forest Gr...    8.0   \n",
       "4922  {\"mailing_address\": \"282 Fourth Trace, Carter ...    7.0   \n",
       "4948  {\"mailing_address\": \"423 Course Trail, Wilmot,...    4.0   \n",
       "4956  {\"mailing_address\": \"251 Grand Rose Underpass,...    7.0   \n",
       "4974  {\"mailing_address\": \"919 Well Overpass, Linden...    2.0   \n",
       "\n",
       "     num_course_taken current_career_path_id time_spent_hrs  \n",
       "15                0.0                   None           None  \n",
       "19               13.0                   None           None  \n",
       "30                5.0                   None           None  \n",
       "49                2.0                   None           None  \n",
       "54               14.0                   None           None  \n",
       "...               ...                    ...            ...  \n",
       "4904             12.0                   None           None  \n",
       "4922              5.0                   None           None  \n",
       "4948              7.0                   None           None  \n",
       "4956              8.0                   None           None  \n",
       "4974             15.0                   None           None  \n",
       "\n",
       "[471 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"current_career_path_id values\")\n",
    "df_students[df_students['current_career_path_id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "202ced17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spent_hrs values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>sex</th>\n",
       "      <th>contact_info</th>\n",
       "      <th>job_id</th>\n",
       "      <th>num_course_taken</th>\n",
       "      <th>current_career_path_id</th>\n",
       "      <th>time_spent_hrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Norene Dalton</td>\n",
       "      <td>1976-04-30</td>\n",
       "      <td>F</td>\n",
       "      <td>{\"mailing_address\": \"130 Wishing Essex, Branch...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Sofia van Steenbergen</td>\n",
       "      <td>1990-02-21</td>\n",
       "      <td>N</td>\n",
       "      <td>{\"mailing_address\": \"634 Clear Barn Dell, Beam...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Christoper Warner</td>\n",
       "      <td>1989-12-28</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"556 Stony Highlands, Drai...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>Antony Horne</td>\n",
       "      <td>1996-05-29</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"P.O. Box 78685, Lenox, Te...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>Omar Bunk</td>\n",
       "      <td>1955-11-08</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"445 Dale Hollow, Vermont ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4904</th>\n",
       "      <td>4905</td>\n",
       "      <td>Eduardo Daniel</td>\n",
       "      <td>2004-06-18</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"598 Deer Trace, Forest Gr...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>4923</td>\n",
       "      <td>Francisco van Ede</td>\n",
       "      <td>1961-04-26</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"282 Fourth Trace, Carter ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>4949</td>\n",
       "      <td>Dewitt van Malsem</td>\n",
       "      <td>1949-03-08</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"423 Course Trail, Wilmot,...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>4957</td>\n",
       "      <td>Todd Stamhuis</td>\n",
       "      <td>1961-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"251 Grand Rose Underpass,...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>4975</td>\n",
       "      <td>Jorge Creelman</td>\n",
       "      <td>1944-11-24</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"919 Well Overpass, Linden...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>471 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uuid                   name         dob sex  \\\n",
       "15      16          Norene Dalton  1976-04-30   F   \n",
       "19      20  Sofia van Steenbergen  1990-02-21   N   \n",
       "30      31      Christoper Warner  1989-12-28   M   \n",
       "49      50           Antony Horne  1996-05-29   M   \n",
       "54      55              Omar Bunk  1955-11-08   M   \n",
       "...    ...                    ...         ...  ..   \n",
       "4904  4905         Eduardo Daniel  2004-06-18   M   \n",
       "4922  4923      Francisco van Ede  1961-04-26   M   \n",
       "4948  4949      Dewitt van Malsem  1949-03-08   M   \n",
       "4956  4957          Todd Stamhuis  1961-06-15   M   \n",
       "4974  4975         Jorge Creelman  1944-11-24   M   \n",
       "\n",
       "                                           contact_info job_id  \\\n",
       "15    {\"mailing_address\": \"130 Wishing Essex, Branch...    6.0   \n",
       "19    {\"mailing_address\": \"634 Clear Barn Dell, Beam...    7.0   \n",
       "30    {\"mailing_address\": \"556 Stony Highlands, Drai...    2.0   \n",
       "49    {\"mailing_address\": \"P.O. Box 78685, Lenox, Te...    3.0   \n",
       "54    {\"mailing_address\": \"445 Dale Hollow, Vermont ...    3.0   \n",
       "...                                                 ...    ...   \n",
       "4904  {\"mailing_address\": \"598 Deer Trace, Forest Gr...    8.0   \n",
       "4922  {\"mailing_address\": \"282 Fourth Trace, Carter ...    7.0   \n",
       "4948  {\"mailing_address\": \"423 Course Trail, Wilmot,...    4.0   \n",
       "4956  {\"mailing_address\": \"251 Grand Rose Underpass,...    7.0   \n",
       "4974  {\"mailing_address\": \"919 Well Overpass, Linden...    2.0   \n",
       "\n",
       "     num_course_taken current_career_path_id time_spent_hrs  \n",
       "15                0.0                   None           None  \n",
       "19               13.0                   None           None  \n",
       "30                5.0                   None           None  \n",
       "49                2.0                   None           None  \n",
       "54               14.0                   None           None  \n",
       "...               ...                    ...            ...  \n",
       "4904             12.0                   None           None  \n",
       "4922              5.0                   None           None  \n",
       "4948              7.0                   None           None  \n",
       "4956              8.0                   None           None  \n",
       "4974             15.0                   None           None  \n",
       "\n",
       "[471 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"time_spent_hrs values\")\n",
    "df_students[df_students['time_spent_hrs'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21ef6030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>sex</th>\n",
       "      <th>contact_info</th>\n",
       "      <th>job_id</th>\n",
       "      <th>num_course_taken</th>\n",
       "      <th>current_career_path_id</th>\n",
       "      <th>time_spent_hrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Doug Browning</td>\n",
       "      <td>1970-06-08</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"P.O. Box 15845, Devine, F...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Damon Schrauwen</td>\n",
       "      <td>1953-10-31</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"P.O. Box 84659, Maben, Ge...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>Alisa Neil</td>\n",
       "      <td>1977-05-28</td>\n",
       "      <td>F</td>\n",
       "      <td>{\"mailing_address\": \"16 View Annex, Mosses, No...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>Chauncey Hooper</td>\n",
       "      <td>1962-04-07</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"955 Dewy Flat, Slaughterv...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81</td>\n",
       "      <td>Ellyn van Heest</td>\n",
       "      <td>1984-06-28</td>\n",
       "      <td>F</td>\n",
       "      <td>{\"mailing_address\": \"872 Cider Glade, Chicken,...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>4890</td>\n",
       "      <td>Tegan Cochran</td>\n",
       "      <td>1970-11-08</td>\n",
       "      <td>F</td>\n",
       "      <td>{\"mailing_address\": \"106 Sunny Nook, Vernal, G...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>4899</td>\n",
       "      <td>Ruthann Oliver</td>\n",
       "      <td>1998-05-22</td>\n",
       "      <td>F</td>\n",
       "      <td>{\"mailing_address\": \"644 Merry Island, Green V...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914</th>\n",
       "      <td>4915</td>\n",
       "      <td>Ernest Holmes</td>\n",
       "      <td>1995-03-11</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"872 Wintergreen Harbor, G...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>4981</td>\n",
       "      <td>Brice Franklin</td>\n",
       "      <td>1946-12-01</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"947 Panda Way, New Bedfor...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>4986</td>\n",
       "      <td>Russel Vonck</td>\n",
       "      <td>1994-09-07</td>\n",
       "      <td>M</td>\n",
       "      <td>{\"mailing_address\": \"815 Middle Timber Corner,...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uuid             name         dob sex  \\\n",
       "25      26    Doug Browning  1970-06-08   M   \n",
       "26      27  Damon Schrauwen  1953-10-31   M   \n",
       "51      52       Alisa Neil  1977-05-28   F   \n",
       "70      71  Chauncey Hooper  1962-04-07   M   \n",
       "80      81  Ellyn van Heest  1984-06-28   F   \n",
       "...    ...              ...         ...  ..   \n",
       "4889  4890    Tegan Cochran  1970-11-08   F   \n",
       "4898  4899   Ruthann Oliver  1998-05-22   F   \n",
       "4914  4915    Ernest Holmes  1995-03-11   M   \n",
       "4980  4981   Brice Franklin  1946-12-01   M   \n",
       "4985  4986     Russel Vonck  1994-09-07   M   \n",
       "\n",
       "                                           contact_info job_id  \\\n",
       "25    {\"mailing_address\": \"P.O. Box 15845, Devine, F...    7.0   \n",
       "26    {\"mailing_address\": \"P.O. Box 84659, Maben, Ge...    4.0   \n",
       "51    {\"mailing_address\": \"16 View Annex, Mosses, No...    5.0   \n",
       "70    {\"mailing_address\": \"955 Dewy Flat, Slaughterv...    3.0   \n",
       "80    {\"mailing_address\": \"872 Cider Glade, Chicken,...    3.0   \n",
       "...                                                 ...    ...   \n",
       "4889  {\"mailing_address\": \"106 Sunny Nook, Vernal, G...    5.0   \n",
       "4898  {\"mailing_address\": \"644 Merry Island, Green V...    3.0   \n",
       "4914  {\"mailing_address\": \"872 Wintergreen Harbor, G...    7.0   \n",
       "4980  {\"mailing_address\": \"947 Panda Way, New Bedfor...    4.0   \n",
       "4985  {\"mailing_address\": \"815 Middle Timber Corner,...    5.0   \n",
       "\n",
       "     num_course_taken current_career_path_id time_spent_hrs  \n",
       "25               None                    5.0           1.92  \n",
       "26               None                   10.0           3.73  \n",
       "51               None                    8.0          22.86  \n",
       "70               None                    3.0           3.97  \n",
       "80               None                   10.0          12.39  \n",
       "...               ...                    ...            ...  \n",
       "4889             None                    8.0          22.75  \n",
       "4898             None                    7.0          21.27  \n",
       "4914             None                    9.0           26.5  \n",
       "4980             None                    5.0           8.66  \n",
       "4985             None                    5.0          16.44  \n",
       "\n",
       "[251 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students[df_students['num_course_taken'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb4f700",
   "metadata": {},
   "source": [
    "It seems that time spent is related to the select career path as the same number of records are missing these, \n",
    "while job id and course taken are unrelated and seem to be missing randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a78b12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in missing values with 0\n",
    "\n",
    "df_students['job_id'] = df_students['job_id'].fillna(0)\n",
    "df_students['num_course_taken'] = df_students['num_course_taken'].fillna(0)\n",
    "df_students['current_career_path_id'] = df_students['current_career_path_id'].fillna(0)\n",
    "df_students['time_spent_hrs'] = df_students['time_spent_hrs'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fc7160a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uuid                      0.0\n",
       "name                      0.0\n",
       "dob                       0.0\n",
       "sex                       0.0\n",
       "contact_info              0.0\n",
       "job_id                    0.0\n",
       "num_course_taken          0.0\n",
       "current_career_path_id    0.0\n",
       "time_spent_hrs            0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking no missing values left\n",
    "\n",
    "df_students.isna().sum() / df_students.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd85f553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students DF info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   uuid                    5000 non-null   int64 \n",
      " 1   name                    5000 non-null   object\n",
      " 2   dob                     5000 non-null   object\n",
      " 3   sex                     5000 non-null   object\n",
      " 4   contact_info            5000 non-null   object\n",
      " 5   job_id                  5000 non-null   object\n",
      " 6   num_course_taken        5000 non-null   object\n",
      " 7   current_career_path_id  5000 non-null   object\n",
      " 8   time_spent_hrs          5000 non-null   object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 351.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Looking again at the dataframe info,\n",
    "# we might want to assign correct datatypes to numerical columns\n",
    "\n",
    "print(\"Students DF info\")\n",
    "df_students.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2220163c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   uuid                    5000 non-null   int64  \n",
      " 1   name                    5000 non-null   object \n",
      " 2   dob                     5000 non-null   object \n",
      " 3   sex                     5000 non-null   object \n",
      " 4   contact_info            5000 non-null   object \n",
      " 5   job_id                  5000 non-null   int64  \n",
      " 6   num_course_taken        5000 non-null   int64  \n",
      " 7   current_career_path_id  5000 non-null   int64  \n",
      " 8   time_spent_hrs          5000 non-null   float64\n",
      "dtypes: float64(1), int64(4), object(4)\n",
      "memory usage: 351.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Changing datatypes\n",
    "\n",
    "df_students = df_students.astype({'job_id': 'float64', 'num_course_taken': 'float64', 'current_career_path_id': 'float64', 'time_spent_hrs': 'float64'})\n",
    "df_students = df_students.astype({'job_id': 'int64', 'num_course_taken': 'int64', 'current_career_path_id': 'int64'})\n",
    "\n",
    "df_students.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a695a8e8",
   "metadata": {},
   "source": [
    "For numerical values we can use describe method to see if any of the values jump out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16eb19c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>job_id</th>\n",
       "      <th>num_course_taken</th>\n",
       "      <th>current_career_path_id</th>\n",
       "      <th>time_spent_hrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.00000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2500.500000</td>\n",
       "      <td>4.16800</td>\n",
       "      <td>7.155400</td>\n",
       "      <td>4.962800</td>\n",
       "      <td>10.435382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1443.520003</td>\n",
       "      <td>2.15107</td>\n",
       "      <td>4.784415</td>\n",
       "      <td>3.169263</td>\n",
       "      <td>7.946934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1250.750000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2500.500000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.665000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3750.250000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>15.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>35.980000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              uuid      job_id  num_course_taken  current_career_path_id  \\\n",
       "count  5000.000000  5000.00000       5000.000000             5000.000000   \n",
       "mean   2500.500000     4.16800          7.155400                4.962800   \n",
       "std    1443.520003     2.15107          4.784415                3.169263   \n",
       "min       1.000000     0.00000          0.000000                0.000000   \n",
       "25%    1250.750000     2.00000          3.000000                2.000000   \n",
       "50%    2500.500000     4.00000          7.000000                5.000000   \n",
       "75%    3750.250000     6.00000         11.000000                8.000000   \n",
       "max    5000.000000     8.00000         15.000000               10.000000   \n",
       "\n",
       "       time_spent_hrs  \n",
       "count     5000.000000  \n",
       "mean        10.435382  \n",
       "std          7.946934  \n",
       "min          0.000000  \n",
       "25%          3.680000  \n",
       "50%          9.665000  \n",
       "75%         15.840000  \n",
       "max         35.980000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ef3ac",
   "metadata": {},
   "source": [
    "In column contact info we seem to have two pieces of information - email and mailing address, which we can extract into separate columns for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5daecc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"mailing_address\": \"303 N Timber Key, Irondale, Wisconsin, 84736\", \"email\": \"annabelle_avery9376@woohoo.com\"}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students['contact_info'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a62f5e",
   "metadata": {},
   "source": [
    "The format represents a JSON, so we can unpack values using the following function that takes care of possible exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63da6e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to convert to json\n",
    "def to_json(row, field):\n",
    "    try:\n",
    "        return json.loads(row).get(field, None)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        print(f\"Version {version}: Failed to parse JSON in row: {row}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b1d0f7",
   "metadata": {},
   "source": [
    "Now let's extract values and drop the contact info column as we no longer need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "134f3953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>sex</th>\n",
       "      <th>job_id</th>\n",
       "      <th>num_course_taken</th>\n",
       "      <th>current_career_path_id</th>\n",
       "      <th>time_spent_hrs</th>\n",
       "      <th>mailing_address</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Annabelle Avery</td>\n",
       "      <td>1943-07-03</td>\n",
       "      <td>F</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4.99</td>\n",
       "      <td>303 N Timber Key, Irondale, Wisconsin, 84736</td>\n",
       "      <td>annabelle_avery9376@woohoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Micah Rubio</td>\n",
       "      <td>1991-02-07</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4.40</td>\n",
       "      <td>767 Crescent Fair, Shoals, Indiana, 37439</td>\n",
       "      <td>rubio6772@hmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hosea Dale</td>\n",
       "      <td>1989-12-07</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6.74</td>\n",
       "      <td>P.O. Box 41269, St. Bonaventure, Virginia, 83637</td>\n",
       "      <td>hosea_dale8084@coldmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mariann Kirk</td>\n",
       "      <td>1988-07-31</td>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>12.31</td>\n",
       "      <td>517 SE Wintergreen Isle, Lane, Arkansas, 82242</td>\n",
       "      <td>kirk4005@hmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Lucio Alexander</td>\n",
       "      <td>1963-08-31</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18 Cinder Cliff, Doyles borough, Rhode Island,...</td>\n",
       "      <td>alexander9810@hmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uuid             name         dob sex  job_id  num_course_taken  \\\n",
       "0     1  Annabelle Avery  1943-07-03   F       7                 6   \n",
       "1     2      Micah Rubio  1991-02-07   M       7                 5   \n",
       "2     3       Hosea Dale  1989-12-07   M       7                 8   \n",
       "3     4     Mariann Kirk  1988-07-31   F       6                 7   \n",
       "4     5  Lucio Alexander  1963-08-31   M       7                14   \n",
       "\n",
       "   current_career_path_id  time_spent_hrs  \\\n",
       "0                       1            4.99   \n",
       "1                       8            4.40   \n",
       "2                       8            6.74   \n",
       "3                       9           12.31   \n",
       "4                       3            5.64   \n",
       "\n",
       "                                     mailing_address  \\\n",
       "0       303 N Timber Key, Irondale, Wisconsin, 84736   \n",
       "1          767 Crescent Fair, Shoals, Indiana, 37439   \n",
       "2   P.O. Box 41269, St. Bonaventure, Virginia, 83637   \n",
       "3     517 SE Wintergreen Isle, Lane, Arkansas, 82242   \n",
       "4  18 Cinder Cliff, Doyles borough, Rhode Island,...   \n",
       "\n",
       "                            email  \n",
       "0  annabelle_avery9376@woohoo.com  \n",
       "1             rubio6772@hmail.com  \n",
       "2     hosea_dale8084@coldmail.com  \n",
       "3              kirk4005@hmail.com  \n",
       "4         alexander9810@hmail.com  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students['mailing_address'] = df_students['contact_info'].apply(lambda x: to_json(x, 'mailing_address'))\n",
    "df_students['email'] = df_students['contact_info'].apply(lambda x: to_json(x, 'email'))\n",
    "df_students = df_students.drop(columns= {'contact_info'})\n",
    "df_students.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8702d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder colums logically\n",
    "df_students = df_students[[\"uuid\", \"name\", \"dob\", \"sex\", \"mailing_address\", \"email\", \"job_id\", \"num_course_taken\", \"current_career_path_id\", \"time_spent_hrs\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25116976",
   "metadata": {},
   "source": [
    "Next we check if the dataframe contains any duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91590a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 in the df_students dataframe\n"
     ]
    }
   ],
   "source": [
    "df_students_duplicates = df_students.duplicated().sum()\n",
    "print(f'There are {df_students_duplicates} in the df_students dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e1b98",
   "metadata": {},
   "source": [
    "We can also check if the same people could have been recorded more than once by combining Name, DOB and email columns and checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c25206c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students_person_info = df_students['name'] + \" \" + df_students['dob'] + \" \" + df_students['email']\n",
    "df_students_person_info.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f726e",
   "metadata": {},
   "source": [
    "###  Import and explore 'cademycode_courses' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24f29ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_query = \"\"\"SELECT * FROM cademycode_courses\"\"\"\n",
    "df_courses = pd.read_sql_query(courses_query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d24572d-b7c0-43ef-8178-d0b6fc29d6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   career_path_id     10 non-null     int64 \n",
      " 1   career_path_name   10 non-null     object\n",
      " 2   hours_to_complete  10 non-null     int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 368.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_courses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b05a9010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Courses DF first 10 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>career_path_id</th>\n",
       "      <th>career_path_name</th>\n",
       "      <th>hours_to_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>software engineering</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>backend engineer</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>frontend engineer</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>iOS developer</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>android developer</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>machine learning engineer</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>ux/ui designer</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   career_path_id           career_path_name  hours_to_complete\n",
       "0               1             data scientist                 20\n",
       "1               2              data engineer                 20\n",
       "2               3               data analyst                 12\n",
       "3               4       software engineering                 25\n",
       "4               5           backend engineer                 18\n",
       "5               6          frontend engineer                 20\n",
       "6               7              iOS developer                 27\n",
       "7               8          android developer                 27\n",
       "8               9  machine learning engineer                 35\n",
       "9              10             ux/ui designer                 15"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nCourses DF first 10 rows\")\n",
    "df_courses.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc57b9a8-9cd6-48fc-899f-ae6c63687d20",
   "metadata": {},
   "source": [
    "Inspect for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a117c275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 in the df_students dataframe\n"
     ]
    }
   ],
   "source": [
    "df_courses_duplicates = df_courses.duplicated().sum()\n",
    "print(f'There are {df_courses_duplicates} in the df_students dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255c32cb",
   "metadata": {},
   "source": [
    "###  Import and explore 'cademycode_jobs' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fb74c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_query = \"\"\"SELECT * FROM cademycode_student_jobs\"\"\"\n",
    "df_jobs = pd.read_sql_query(jobs_query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcd321f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs DF info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13 entries, 0 to 12\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   job_id        13 non-null     int64 \n",
      " 1   job_category  13 non-null     object\n",
      " 2   avg_salary    13 non-null     int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 440.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Jobs DF info\")\n",
    "df_jobs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a16c8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jobs DF first 10 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_category</th>\n",
       "      <th>avg_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>analytics</td>\n",
       "      <td>86000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>engineer</td>\n",
       "      <td>101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>software developer</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>creative</td>\n",
       "      <td>66000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>financial services</td>\n",
       "      <td>135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>education</td>\n",
       "      <td>61000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>HR</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>student</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>other</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id        job_category  avg_salary\n",
       "0       1           analytics       86000\n",
       "1       2            engineer      101000\n",
       "2       3  software developer      110000\n",
       "3       4            creative       66000\n",
       "4       5  financial services      135000\n",
       "5       6           education       61000\n",
       "6       7                  HR       80000\n",
       "7       8             student       10000\n",
       "8       9          healthcare      120000\n",
       "9       0               other       80000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nJobs DF first 10 rows\")\n",
    "df_jobs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60900ce6-0332-4106-b625-2263f1fe96aa",
   "metadata": {},
   "source": [
    "Inspect the dataframe for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d72f6c9-9eab-4b3a-9923-a87f29ac6a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 in the df_students dataframe\n"
     ]
    }
   ],
   "source": [
    "df_jobs_duplicates = df_jobs.duplicated().sum()\n",
    "print(f'There are {df_jobs_duplicates} in the df_students dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3e3491-b5af-4814-9c43-0581199ce50c",
   "metadata": {},
   "source": [
    "As there are duplicates in the dataframe, we can introduce an if statement that runs drop_duplicates if there are any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf572733-8f69-43a7-99ab-7cd104b0a55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cademycode_job table contains 3 duplicates\n"
     ]
    }
   ],
   "source": [
    "if df_jobs_duplicates > 0:\n",
    "    print(f\"cademycode_job table contains {df_jobs_duplicates} duplicates\")\n",
    "    df_jobs = df_jobs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28307ba4-c847-446b-adb8-20211caded6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 in the df_students dataframe\n"
     ]
    }
   ],
   "source": [
    "df_jobs_duplicates = df_jobs.duplicated().sum()\n",
    "print(f'There are {df_jobs_duplicates} in the df_students dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e698c98",
   "metadata": {},
   "source": [
    "## Create the Output CSV ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72391a52",
   "metadata": {},
   "source": [
    "Use the cleaned tables to produce an analytics-ready SQLite database and flat CSV file. The final CSV should contain all the data the analysts might need in a single table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000282e3",
   "metadata": {},
   "source": [
    "###  Transforming the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2930a33e-4c16-4991-83db-46944b5a51d9",
   "metadata": {},
   "source": [
    "Now that data is cleaned, we can proceed to joining the dataframes to create a single view for an analysts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58b79994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging students and courses dataframes\n",
    "\n",
    "df_merged = pd.merge(df_students, df_courses,  how='left', left_on=\"current_career_path_id\", right_on=\"career_path_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a31c64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following with the merge of jobs dataframe\n",
    "\n",
    "df_final = pd.merge(df_merged, df_jobs, how=\"left\", left_on=\"job_id\", right_on=\"job_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0315ae9d-325d-4097-b95c-1e553b712fb2",
   "metadata": {},
   "source": [
    "Checking the numbers of rows before and after the merge operations to ensure the number of students doesn't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "500cfc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape[0] - df_students.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6d6600-fb74-4233-88aa-03f0fc039b59",
   "metadata": {},
   "source": [
    "We can also check for any empty values in the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cbe8597-71b1-4629-8abe-8091f3002181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uuid                        0\n",
       "name                        0\n",
       "dob                         0\n",
       "sex                         0\n",
       "mailing_address             0\n",
       "email                       0\n",
       "job_id                      0\n",
       "num_course_taken            0\n",
       "current_career_path_id      0\n",
       "time_spent_hrs              0\n",
       "career_path_id            471\n",
       "career_path_name          471\n",
       "hours_to_complete         471\n",
       "job_category                0\n",
       "avg_salary                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f56de5b0-eba4-49d9-9550-ad5e008979f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"avg_salary\"] = df_final[\"avg_salary\"].fillna(0)\n",
    "df_final[\"career_path_name\"] = df_final[\"career_path_name\"].fillna('Unknown')\n",
    "df_final[\"hours_to_complete\"] = df_final[\"hours_to_complete\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "259e237e-6937-40b2-ac5a-96db68b718ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uuid                        0\n",
       "name                        0\n",
       "dob                         0\n",
       "sex                         0\n",
       "mailing_address             0\n",
       "email                       0\n",
       "job_id                      0\n",
       "num_course_taken            0\n",
       "current_career_path_id      0\n",
       "time_spent_hrs              0\n",
       "career_path_id            471\n",
       "career_path_name            0\n",
       "hours_to_complete           0\n",
       "job_category                0\n",
       "avg_salary                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ecc24-a1df-4338-a7ed-f7f6d4f22dbc",
   "metadata": {},
   "source": [
    "We can drop career_path_id columns as we have current_career_path_id from the students dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce565fe1-87da-4e7f-92e3-25f6e8d78f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop(columns=\"career_path_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95655dcf-6876-4070-b549-addb916f1100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uuid                      0\n",
       "name                      0\n",
       "dob                       0\n",
       "sex                       0\n",
       "mailing_address           0\n",
       "email                     0\n",
       "job_id                    0\n",
       "num_course_taken          0\n",
       "current_career_path_id    0\n",
       "time_spent_hrs            0\n",
       "career_path_name          0\n",
       "hours_to_complete         0\n",
       "job_category              0\n",
       "avg_salary                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c316967-9226-4bb6-836d-8349baa5b1ad",
   "metadata": {},
   "source": [
    "Knowing hours required to complete a career path and time spent studying, we can see if a student completed a path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a6e76e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['_completed_path'] = df_final.apply(\n",
    "    lambda row: False if pd.isna(row['time_spent_hrs']) or pd.isna(row['hours_to_complete']) else row['time_spent_hrs'] > row['hours_to_complete'], \n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cd8324e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>sex</th>\n",
       "      <th>mailing_address</th>\n",
       "      <th>email</th>\n",
       "      <th>job_id</th>\n",
       "      <th>num_course_taken</th>\n",
       "      <th>current_career_path_id</th>\n",
       "      <th>time_spent_hrs</th>\n",
       "      <th>career_path_name</th>\n",
       "      <th>hours_to_complete</th>\n",
       "      <th>job_category</th>\n",
       "      <th>avg_salary</th>\n",
       "      <th>_completed_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Annabelle Avery</td>\n",
       "      <td>1943-07-03</td>\n",
       "      <td>F</td>\n",
       "      <td>303 N Timber Key, Irondale, Wisconsin, 84736</td>\n",
       "      <td>annabelle_avery9376@woohoo.com</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4.99</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>20.0</td>\n",
       "      <td>HR</td>\n",
       "      <td>80000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Micah Rubio</td>\n",
       "      <td>1991-02-07</td>\n",
       "      <td>M</td>\n",
       "      <td>767 Crescent Fair, Shoals, Indiana, 37439</td>\n",
       "      <td>rubio6772@hmail.com</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4.40</td>\n",
       "      <td>android developer</td>\n",
       "      <td>27.0</td>\n",
       "      <td>HR</td>\n",
       "      <td>80000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hosea Dale</td>\n",
       "      <td>1989-12-07</td>\n",
       "      <td>M</td>\n",
       "      <td>P.O. Box 41269, St. Bonaventure, Virginia, 83637</td>\n",
       "      <td>hosea_dale8084@coldmail.com</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6.74</td>\n",
       "      <td>android developer</td>\n",
       "      <td>27.0</td>\n",
       "      <td>HR</td>\n",
       "      <td>80000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mariann Kirk</td>\n",
       "      <td>1988-07-31</td>\n",
       "      <td>F</td>\n",
       "      <td>517 SE Wintergreen Isle, Lane, Arkansas, 82242</td>\n",
       "      <td>kirk4005@hmail.com</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>12.31</td>\n",
       "      <td>machine learning engineer</td>\n",
       "      <td>35.0</td>\n",
       "      <td>education</td>\n",
       "      <td>61000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Lucio Alexander</td>\n",
       "      <td>1963-08-31</td>\n",
       "      <td>M</td>\n",
       "      <td>18 Cinder Cliff, Doyles borough, Rhode Island,...</td>\n",
       "      <td>alexander9810@hmail.com</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>5.64</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>12.0</td>\n",
       "      <td>HR</td>\n",
       "      <td>80000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uuid             name         dob sex  \\\n",
       "0     1  Annabelle Avery  1943-07-03   F   \n",
       "1     2      Micah Rubio  1991-02-07   M   \n",
       "2     3       Hosea Dale  1989-12-07   M   \n",
       "3     4     Mariann Kirk  1988-07-31   F   \n",
       "4     5  Lucio Alexander  1963-08-31   M   \n",
       "\n",
       "                                     mailing_address  \\\n",
       "0       303 N Timber Key, Irondale, Wisconsin, 84736   \n",
       "1          767 Crescent Fair, Shoals, Indiana, 37439   \n",
       "2   P.O. Box 41269, St. Bonaventure, Virginia, 83637   \n",
       "3     517 SE Wintergreen Isle, Lane, Arkansas, 82242   \n",
       "4  18 Cinder Cliff, Doyles borough, Rhode Island,...   \n",
       "\n",
       "                            email  job_id  num_course_taken  \\\n",
       "0  annabelle_avery9376@woohoo.com       7                 6   \n",
       "1             rubio6772@hmail.com       7                 5   \n",
       "2     hosea_dale8084@coldmail.com       7                 8   \n",
       "3              kirk4005@hmail.com       6                 7   \n",
       "4         alexander9810@hmail.com       7                14   \n",
       "\n",
       "   current_career_path_id  time_spent_hrs           career_path_name  \\\n",
       "0                       1            4.99             data scientist   \n",
       "1                       8            4.40          android developer   \n",
       "2                       8            6.74          android developer   \n",
       "3                       9           12.31  machine learning engineer   \n",
       "4                       3            5.64               data analyst   \n",
       "\n",
       "   hours_to_complete job_category  avg_salary  _completed_path  \n",
       "0               20.0           HR       80000            False  \n",
       "1               27.0           HR       80000            False  \n",
       "2               27.0           HR       80000            False  \n",
       "3               35.0    education       61000            False  \n",
       "4               12.0           HR       80000            False  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the new columns has been added\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d2ec88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any empty values in the final dataframe\n",
    "\n",
    "df_final.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecddf4aa",
   "metadata": {},
   "source": [
    "### Loading data into a new table in sqlite3 and exporting as CSV ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3099cef-527b-4073-9c47-0165a238c62c",
   "metadata": {},
   "source": [
    "After the data is clean and combined into a single view, we export it into a new DB table and a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84276507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_sql(name='students_data', con=con, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208678b8-cafb-41ef-80a0-f6150f01b2d6",
   "metadata": {},
   "source": [
    "Check if the table has been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa12ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_students_data_query = \"\"\"SELECT * FROM students_data LIMIT 10\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d3eae9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1, 'Annabelle Avery', '1943-07-03', 'F', '303 N Timber Key, Irondale, Wisconsin, 84736', 'annabelle_avery9376@woohoo.com', 7, 6, 1, 4.99, 'data scientist', 20.0, 'HR', 80000, 0), (1, 2, 'Micah Rubio', '1991-02-07', 'M', '767 Crescent Fair, Shoals, Indiana, 37439', 'rubio6772@hmail.com', 7, 5, 8, 4.4, 'android developer', 27.0, 'HR', 80000, 0), (2, 3, 'Hosea Dale', '1989-12-07', 'M', 'P.O. Box 41269, St. Bonaventure, Virginia, 83637', 'hosea_dale8084@coldmail.com', 7, 8, 8, 6.74, 'android developer', 27.0, 'HR', 80000, 0), (3, 4, 'Mariann Kirk', '1988-07-31', 'F', '517 SE Wintergreen Isle, Lane, Arkansas, 82242', 'kirk4005@hmail.com', 6, 7, 9, 12.31, 'machine learning engineer', 35.0, 'education', 61000, 0), (4, 5, 'Lucio Alexander', '1963-08-31', 'M', '18 Cinder Cliff, Doyles borough, Rhode Island, 73737', 'alexander9810@hmail.com', 7, 14, 3, 5.64, 'data analyst', 12.0, 'HR', 80000, 0), (5, 6, 'Shavonda Mcmahon', '1989-10-15', 'F', 'P.O. Box 81591, Tarpon Springs, Montana, 37057', 'shavonda5863@coldmail.com', 6, 10, 3, 10.12, 'data analyst', 12.0, 'education', 61000, 0), (6, 7, 'Terrell Bleijenberg', '1959-05-05', 'M', 'P.O. Box 53471, Oskaloosa, Virginia, 85274', 'bleijenberg188@hmail.com', 2, 9, 8, 24.17, 'android developer', 27.0, 'engineer', 101000, 0), (7, 8, 'Stanford Allan', '1997-11-22', 'M', '255 Spring Avenue, Point Baker, Texas, 15796', 'stanford_allan8055@coldmail.com', 3, 3, 1, 19.54, 'data scientist', 20.0, 'software developer', 110000, 0), (8, 9, 'Tricia Delacruz', '1961-10-20', 'F', '997 Dewy Apple, Lake Lindsey, Washington, 78266', 'tricia_delacruz6622@woohoo.com', 1, 6, 9, 1.75, 'machine learning engineer', 35.0, 'analytics', 86000, 0), (9, 10, 'Regenia van der Helm', '1999-02-23', 'N', '220 Middle Ridge, Falcon Heights, New Mexico, 46971', 'regenia6908@inlook.com', 5, 7, 6, 13.55, 'frontend engineer', 20.0, 'financial services', 135000, 0)]\n"
     ]
    }
   ],
   "source": [
    "print(cur.execute(final_students_data_query).fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52f8f1b-274f-4ec5-9b1e-a86fa29c123e",
   "metadata": {},
   "source": [
    "Now, export the final DF into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a61e6c95-c00b-4f4a-86c8-68b8595589ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('students_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79ac8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf01788-1549-4f29-8d2d-c458c2dc23e1",
   "metadata": {},
   "source": [
    "## Develop Unit Tests and Logs ##\n",
    "Turn the Jupyter Notebook into a Python script that can be run with minimal human intervention.\n",
    "\n",
    "The script should:\n",
    " * check for updates to the database and\n",
    " * use unit tests to protect the update process.\n",
    " \n",
    "Any updates made to the final database should be written to a changelog, and any errors from the unit tests should be written to an error log."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 154,
=======
   "execution_count": 54,
>>>>>>> b55bf586d0b390d80d580e6bb8aae97c0ca59418
   "id": "3d3678d6-c824-433a-8f96-d4c843b4987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 156,
=======
   "execution_count": 55,
>>>>>>> b55bf586d0b390d80d580e6bb8aae97c0ca59418
   "id": "deadf54b-cd3d-476b-94b9-2e5ea4dcd4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    filename='data_pipeline.log', \n",
    "    level=logging.DEBUG, \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%m/%d/%Y %H:%M:%S'\n",
    ")"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": null,
   "id": "b0096988-3b8a-46f3-9805-00afc5d255a4",
=======
   "cell_type": "markdown",
   "id": "cefcdb6e",
   "metadata": {},
   "source": [
    "We set up the following parameters for the logger:\n",
    "* name of the logger file\n",
    "* level is set to DEBUG, so we can see INFO messages and above\n",
    "* the format of the log messages - \"TIME - LEVEL - MESSAGE\"\n",
    "* date format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc704886",
   "metadata": {},
   "source": [
    "Alongside with the logs we want to implement some sort of version tracking to allow for better troubleshooting and logs readibility. For simplicity we use an external file to keep track of the current version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8a0f40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this function we write a simple incremental version update\n",
    "\n",
    "def change_version():\n",
    "    global version\n",
    "    version += 1\n",
    "    return version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e857a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we want to keep track in an external file, we need to write functions for reading from and writing to the file.\n",
    "\n",
    "def read_version():\n",
    "    try:\n",
    "        with open('version.txt', 'r') as file:\n",
    "            version = int(file.read().strip())\n",
    "            return version\n",
    "    except FileNotFoundError:\n",
    "        logger.warning(\"version.txt not found. Starting at version 1.\") # Adding logging for errors\n",
    "        return 1  # Default version\n",
    "    \n",
    "def write_version(version):\n",
    "    try:\n",
    "        with open('version.txt', 'w') as file:\n",
    "            file.write(f\"{version}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error writing to the file: {e}\") # Adding logging for errors when writing to the file\n",
    "        return\n",
    "        \n",
    "# And we can update the change_version function, with the write function call\n",
    "def change_version():\n",
    "    global version\n",
    "    version += 1\n",
    "    logger.info(f\"Version is updated to {version}\") # Adding logging for errors\n",
    "    write_version(version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e3d9c6",
   "metadata": {},
   "source": [
    "Let's test these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "13bd6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the first run it should return 1\n",
    "version = read_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a838f8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f972a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we write it to the file\n",
    "write_version(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e997fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increment verion by 1\n",
    "change_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d54ecb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(read_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b41b8cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Check if the latest version is stored correctly\n",
    "\n",
    "write_version(version)\n",
    "with open('version.txt', 'r') as f:\n",
    "    for row in f:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689cc3f3",
   "metadata": {},
   "source": [
    "In our script we want to only run the pipeline when the database is refreshed,\n",
    "in order to execute that we will need to:\n",
    "* read the file updated at information \n",
    "* compare it against the last time we modified the database\n",
    "* if the last updated time is more recent than our modification time, we run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f9513218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Function to check if the database has been updates since the last run\n",
    "def read_last_modified_time():\n",
    "    try:\n",
    "        with open('last_modified_time.txt', 'r') as f:\n",
    "            timestamp_str = f.read().strip()\n",
    "            if timestamp_str:\n",
    "                return datetime.fromisoformat(timestamp_str)\n",
    "            else:\n",
    "                return None\n",
    "    except FileNotFoundError:\n",
    "        logger.warning(\"last_modified_time.txt not found\") # Adding logging for errors when reading the file\n",
    "        return None\n",
    "    \n",
    "# Function to write last modified time to a file\n",
    "def write_last_modified_time(modified_time):\n",
    "    try:\n",
    "        with open('last_modified_time.txt', 'w') as f:\n",
    "            logger.info(f\"last_modified_time.txt has been updated: {modified_time.isoformat()}\") # Adding debugging information\n",
    "            f.write(modified_time.isoformat())\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error when writing to last_modified_time.txt: {e}\") # Adding logging for errors when writing to the file\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e822a7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-07 21:34:30.299423\n"
     ]
    }
   ],
   "source": [
    "# Pass current time into the write function and read the file to see if it has updated the file\n",
    "\n",
    "write_last_modified_time(datetime.now())\n",
    "print(read_last_modified_time())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9ea320",
   "metadata": {},
   "source": [
    "With us being able to capture the time from the database file and to keep track of modification time, let's write a function that test if the database has been updated which will determine if we need to run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8ca4dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Function to check if the database has been updated\n",
    "def is_database_updated(db_file):\n",
    "    if not os.path.exists(db_file):\n",
    "        logger.error(f\"Database file {db_file} not found.\") # Adding logging for when the db file wasn't found\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        file_info = os.stat(db_file)\n",
    "        file_modified_time = file_info.st_mtime\n",
    "        current_modified_time = datetime.fromtimestamp(file_modified_time)\n",
    "        logger.debug(f'Current modified time is {current_modified_time}') # Track timestamp for debugging\n",
    "        \n",
    "        last_modified_time = read_last_modified_time()\n",
    "        logger.debug(f'Last modified time is {last_modified_time}')\n",
    "        if last_modified_time is None or current_modified_time > last_modified_time:\n",
    "            write_last_modified_time(current_modified_time)\n",
    "            return True\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error checking database modification time: {e}\") # Adding loggin for when we can't check if db is updated \n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b2d3111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Test returns True which means we can run the pipeline\n",
    "\n",
    "print(is_database_updated('cademycode.db'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc46637",
   "metadata": {},
   "source": [
    "Also we can add a few unittests to check the following conditions are met: \n",
    "* The number of rows doesn't change during merging, no duplicates are created\n",
    "* The final data doesn't contain any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7bd1542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestDataPipeline(unittest.TestCase):\n",
    "    def test_number_of_rows(self):\n",
    "        self.assertEqual(df_student_row_count, df_student_data_row_count, \"The number of rows changed during transformation\")\n",
    "    \n",
    "    def test_no_null_values(self):\n",
    "        self.assertFalse(df_final.isnull().values.any(), \"There are null values in the final table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080601b7",
   "metadata": {},
   "source": [
    "## Final python script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036d0492",
   "metadata": {},
   "source": [
    "Adding all parts together alongside with a context manager for relevant files, more logging units and tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c80e7e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.010s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "import unittest\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    filename='data_pipeline.log', \n",
    "    level=logging.DEBUG, \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%m/%d/%Y %H:%M:%S'\n",
    ")\n",
    "\n",
    "# Function to check if the database has been updates since the last run\n",
    "def read_last_modified_time():\n",
    "    try:\n",
    "        with open('last_modified_time.txt', 'r') as f:\n",
    "            timestamp_str = f.read().strip()\n",
    "            if timestamp_str:\n",
    "                return datetime.fromisoformat(timestamp_str)\n",
    "            else:\n",
    "                return None\n",
    "    except FileNotFoundError:\n",
    "        logger.warning(\"last_modified_time.txt not found\")\n",
    "        return None\n",
    "    \n",
    "# Function to write last modified time to a file\n",
    "def write_last_modified_time(modified_time):\n",
    "    try:\n",
    "        with open('last_modified_time.txt', 'w') as f:\n",
    "            logger.info(f\"last_modified_time.txt has been updated: {modified_time.isoformat()}\")\n",
    "            f.write(modified_time.isoformat())\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error when writing to last_modified_time.txt: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to check if the database has been updated\n",
    "def is_database_updated(db_file):\n",
    "    if not os.path.exists(db_file):\n",
    "        logger.error(f\"Database file {db_file} not found.\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        file_info = os.stat(db_file)\n",
    "        file_modified_time = file_info.st_mtime\n",
    "        current_modified_time = datetime.fromtimestamp(file_modified_time)\n",
    "        logger.debug(f'Current modified time is {current_modified_time}')\n",
    "        \n",
    "        last_modified_time = read_last_modified_time()\n",
    "        logger.debug(f'Last modified time is {last_modified_time}')\n",
    "        if last_modified_time is None or current_modified_time > last_modified_time:\n",
    "            write_last_modified_time(current_modified_time)\n",
    "            return True\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error checking database modification time: {e}\")\n",
    "        return False\n",
    "\n",
    "# Function to convert to json\n",
    "def to_json(row, field):\n",
    "    try:\n",
    "        return json.loads(row).get(field, None)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        logger.error(f\"Version {version}: Failed to parse JSON in row: {row}\")\n",
    "        return None\n",
    "\n",
    "# Function to read version from a file\n",
    "def read_version():\n",
    "    try:\n",
    "        with open('version.txt', 'r') as file:\n",
    "            version = int(file.read().strip())\n",
    "            return version\n",
    "    except FileNotFoundError:\n",
    "        logger.warning(\"version.txt not found. Starting at version 1.\")\n",
    "        return 1  # Default version\n",
    "\n",
    "# Function to write updated version to a file\n",
    "def write_version(version):\n",
    "    try:\n",
    "        with open('version.txt', 'w') as file:\n",
    "            file.write(f\"{version}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error writing to the file: {e}\")\n",
    "        return\n",
    "\n",
    "# Function to keep track of versions\n",
    "def change_version():\n",
    "    global version\n",
    "    version += 1\n",
    "    logger.info(f\"Version is updated to {version}\")\n",
    "    write_version(version)\n",
    "\n",
    "# Connection to database and data processing unit\n",
    "try:  \n",
    "    db_file = 'cademycode_updated.db'\n",
    "    last_modified_time = read_last_modified_time()\n",
    "    version = read_version()\n",
    "    change_version()\n",
    "    with sqlite3.connect(db_file) as con:\n",
    "        logger.info(f\"Version {version}: Connected to the database\")\n",
    "        cur = con.cursor()\n",
    "        \n",
    "        if is_database_updated(db_file):\n",
    "            logger.info(f\"Version {version}: Database is updated, executing the pipeline\")\n",
    "            \n",
    "            # Read sql into a dataframe\n",
    "            students_query = \"\"\"SELECT * FROM cademycode_students\"\"\"\n",
    "            df_students = pd.read_sql_query(students_query, con)\n",
    "          \n",
    "            df_students_duplicates_count = df_students.duplicated().sum()\n",
    "            if df_students_duplicates_count > 0:\n",
    "                logger.warning(f\"Version {version}: cademycode_students table contains {df_students_duplicates_count} duplicates\")\n",
    "                df_students = df_students.drop_duplicates()\n",
    "\n",
    "            # Unpack contact_info column into separate columns for address and email\n",
    "            df_students['mailing_address'] = df_students['contact_info'].apply(lambda x: to_json(x, 'mailing_address'))\n",
    "            df_students['email'] = df_students['contact_info'].apply(lambda x: to_json(x, 'email'))\n",
    "            df_students = df_students.drop(columns= {'contact_info'})\n",
    "\n",
    "            # Reorder colums logically and rename\n",
    "            df_students = df_students[[\"uuid\", \"name\", \"dob\", \"sex\", \"mailing_address\", \"email\", \"job_id\", \"num_course_taken\", \"current_career_path_id\", \"time_spent_hrs\"]]\n",
    "            df_students = df_students.rename(columns={\"current_career_path_id\":\"career_path_id\"})\n",
    "\n",
    "            # Fill in empty values\n",
    "            df_students['job_id'] = df_students['job_id'].fillna(0)\n",
    "            df_students['num_course_taken'] = df_students['num_course_taken'].fillna(0)\n",
    "            df_students['career_path_id'] = df_students['career_path_id'].fillna(0)\n",
    "            df_students['time_spent_hrs'] = df_students['time_spent_hrs'].fillna(0)\n",
    "\n",
    "            # Change data types for numerical columns\n",
    "            df_students = df_students.astype({'job_id': 'float64', 'num_course_taken': 'float64', 'career_path_id': 'float64', 'time_spent_hrs': 'float64'})\n",
    "            df_students = df_students.astype({'job_id': 'int64', 'num_course_taken': 'int64', 'career_path_id': 'int64'})\n",
    "\n",
    "            # read sql into a dataframe and change data_types\n",
    "            courses_query = \"\"\"SELECT * FROM cademycode_courses\"\"\"\n",
    "            df_courses = pd.read_sql_query(courses_query, con)\n",
    "          \n",
    "            df_courses_duplicates_count = df_courses.duplicated().sum()\n",
    "            if df_courses_duplicates_count > 0:\n",
    "                logger.warning(f\"Version {version}: cademycode_courses table contains {df_courses_duplicates_count} duplicates\")\n",
    "                df_courses = df_courses.drop_duplicates()\n",
    "            \n",
    "            df_courses = df_courses.astype({'career_path_id': 'int64', 'hours_to_complete': 'int64'})\n",
    "\n",
    "            # read sql into a dataframe and change data_types\n",
    "            jobs_query = \"\"\"SELECT * FROM cademycode_student_jobs\"\"\"\n",
    "            df_jobs = pd.read_sql_query(jobs_query, con)\n",
    "          \n",
    "            df_jobs_duplicates_count = df_jobs.duplicated().sum()\n",
    "            if df_jobs_duplicates_count > 0:\n",
    "                logger.warning(f\"Version {version}: cademycode_job table contains {df_jobs_duplicates_count} duplicates\")\n",
    "                df_jobs = df_jobs.drop_duplicates()\n",
    "          \n",
    "            df_jobs = df_jobs.astype({'job_id': 'int64', 'avg_salary': 'int64'})\n",
    "\n",
    "            df_student_row_count = df_students.shape[0]\n",
    "            logger.info(f\"Version {version}: Number of line before the join: {df_student_row_count}\")\n",
    "\n",
    "            # joining students data with job and courses\n",
    "            df_merged = pd.merge(df_students, df_courses,  how='left', left_on=\"career_path_id\", right_on=\"career_path_id\")\n",
    "            df_final = pd.merge(df_merged, df_jobs, how=\"left\", left_on=\"job_id\", right_on=\"job_id\")\n",
    "\n",
    "            df_student_data_row_count = df_final.shape[0]\n",
    "            logger.info(f\"Version {version}: Number of lines after the join: {df_student_data_row_count}\")\n",
    "\n",
    "            df_final[\"job_category\"] = df_final[\"job_category\"].fillna('Unknown')\n",
    "            df_final[\"avg_salary\"] = df_final[\"avg_salary\"].fillna(0)\n",
    "            df_final[\"career_path_name\"] = df_final[\"career_path_name\"].fillna('Unknown')\n",
    "            df_final[\"hours_to_complete\"] = df_final[\"hours_to_complete\"].fillna(0)\n",
    "\n",
    "            # checking if the table doesn't contain duplicated student as a result of the join\n",
    "            if df_student_row_count == df_student_data_row_count:\n",
    "                logger.info(f\"Version {version}: Number of students remains the same after the join\")\n",
    "            else: \n",
    "                logger.error(f\"Version {version}: Number of students changes after the join\")\n",
    "\n",
    "            # if hours spent equals or more than needed hours to complete a path - then true\n",
    "            df_final['_completed_path'] = (df_final['time_spent_hrs'] > df_final['hours_to_complete']).fillna(False)\n",
    "\n",
    "            # load the final table into the database and export as a csv file\n",
    "            db_table = \"students_data\"\n",
    "            df_final.to_sql(name=db_table, con=con, if_exists=\"replace\")\n",
    "            logger.info(f\"Version {version}: Updating the DB table - {db_table}\")\n",
    "            \n",
    "            file_path = \"students_data.csv\"\n",
    "            df_final.to_csv(file_path, index=False)\n",
    "            logger.info(f\"Version {version}: Exporting file to {file_path}\")\n",
    "        else: \n",
    "            logger.info(f\"Version {version}: Database has no updates\")\n",
    "\n",
    "except Exception as e:\n",
    "      logger.error(f\"Version {version}: Error running the pipeline: {e}\")\n",
    "      raise\n",
    "\n",
    "class TestDataPipeline(unittest.TestCase):\n",
    "    def test_number_of_rows(self):\n",
    "        self.assertEqual(df_student_row_count, df_student_data_row_count, \"The number of rows changed during transformation\")\n",
    "    \n",
    "    def test_no_null_values(self):\n",
    "        self.assertFalse(df_final.isnull().values.any(), \"There are null values in the final table\")\n",
    "\n",
    "df_student_row_count = df_students.shape[0]\n",
    "df_student_data_row_count = df_final.shape[0]\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02d5a4b",
   "metadata": {},
   "source": [
    "## Create a Bash Script ##\n",
    "\n",
    "Create a bash script to handle running the Python script and moving updated files from your working directory in /dev to a production directory. Your bash script should use the logs from the last task to determine if an update occurred.\n",
    "\n",
    "* Execute python file within bash scripts\n",
    "* Move the file over to the production folder\n",
    "* Use version numbers in your changelog to check for updates"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e230edef",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "\n",
    "# Set up script variables\n",
    "PYTHON_SCRIPT=\"data_pipeline.py\"\n",
    "VERSION_FILE=\"version.txt\"\n",
    "LOG_FILE=\"data_pipeline.log\"\n",
    "PROD_DIR=\"../prod\"\n",
    "EXCEL_FILE=\"students_data.csv\"\n",
    "\n",
    "# Execute Python script\n",
    "echo \"Running pipeline\"\n",
    "python3 $PYTHON_SCRIPT\n",
    "\n",
    "# Check the latest version from the versions file\n",
    "LATEST_VERSION=$(head -n 1 $VERSION_FILE)\n",
    "\n",
    "# Check logs if any errors occured\n",
    "if grep -A 100 \"Version $LATEST_VERSION\" \"$LOG_FILE\" | grep -q \"ERROR\"\n",
    "then \n",
    "  echo \"Pipeline failed in version $LATEST_VERSION. Check the logs for more details.\"\n",
    "  # Exit the script with an error code\n",
    "  exit 1 \n",
    "else\n",
    "  echo \"Pipeline version $LATEST_VERSION completed successfully.\"\n",
    "fi\n",
    "\n",
    "# Move files from dev into prod\n",
    "if [ ! -d \"$PROD_DIR\" ]; then\n",
    "    mkdir -p \"$PROD_DIR\"\n",
    "    echo \"Created production directory: $PROD_DIR\"\n",
    "fi\n",
    "\n",
    "mv \"$EXCEL_FILE\" \"$PROD_DIR\"\n",
    "echo \"File moved to $PROD_DIR\"\n",
    "\n",
    "echo \"Finished the pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edc621f",
   "metadata": {},
   "source": [
    "So the bash script runs the python, then checks the log to see the recent version of the run and if there were any errors,\n",
    "if not - the bash script moved files into the dev directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3fbbc7",
   "metadata": {},
   "source": [
    "## Create a Readme ##\n",
    "Create a readme.md file for your update process. This file should describe the folder structure of your final project and include instructions for how to run your Bash script to update the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c34789",
   "metadata": {},
   "source": [
    "Think about what information someone would need to know to run your update process:\n",
    "\n",
    " * what each file does, and where it lives\n",
    " * how to run the update process\n",
    " * how any changelogs or other version control systems you’ve created operate\n",
    " * where errors are logged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0208e9e6",
   "metadata": {},
   "source": [
    "## Data pipeline project\n",
    "### Overview\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00dbc75e",
   "metadata": {},
   "source": [
    "|--dev\n",
    "| |--data_pipeline.py\n",
    "| |--script.sh\n",
    "|--prod\n",
    "| |--students_data.csv\n",
    "|--log\n",
    "| |--data_pipeline.log\n",
    "| |--version.txt\n",
    "| |--last_modified_time.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381f094f",
   "metadata": {},
   "source": [
    "## Create a Writeup\n",
    "\n",
    "Write a high-level overview of the project to share in your portfolio. This is for your portfolio, so include your thought process in addition to the actual steps you took.\n",
    "\n",
    "Here are some prompts to help you get started:\n",
    "\n",
    "- What data cleaning operations did you do, and why?\n",
    "- What kinds of unit tests did you use? Why did you pick those?\n",
    "- How did you structure the automation of the bash script?\n",
    "- What steps did you take to protect the final database from being incorrectly updated?\n",
    "\n",
    "Remember, you are trying to demonstrate your skills in:\n",
    "\n",
    "- Data cleaning and wrangling\n",
    "- Unit tests and error logging\n",
    "- Bash scripting\n",
    "- SQLite databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ace7ba",
>>>>>>> b55bf586d0b390d80d580e6bb8aae97c0ca59418
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
